{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Cartpole.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnwiese/dqn-cart-poleV2/blob/master/Cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6oLC1-jCFYM",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_UdPif-CFYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import deque\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-c1mIEuCFYR",
        "colab_type": "text"
      },
      "source": [
        "## Initialize class\n",
        "Class is initialized with 4 XGBRegressor models, one for each state feature, and one XGBClassifier model.\n",
        "Training data is collected in state-action pairs. \n",
        "Each XGBRegressor model is fit using the training data with one timestep offset, so for a given model current state feature is predicted by previous state-action.\n",
        "A custom reward function is used where selected state feature closest to zero is given highest reward - in this case the pole angle is used as selected state feature for the custom reward function.\n",
        "Action at current state is selected based on predicted state at timestep t+n with the highest reward.\n",
        "\n",
        "On a successfully completed episode data is passed to the XGBClassifier to be trained. A \"switch\" variable is used to gradually, after each successful epsidode, hand over the action selection to this second layer. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGAUxygBCFYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XGBAgent(object):\n",
        "\n",
        "    def __init__(self, ma_training_data_size, mb_training_data_size, ma_mb_switch):\n",
        "\n",
        "        self.env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "        self.action_space = self.env.action_space.n\n",
        "        self.observation_space_n = self.env.observation_space.shape[0]\n",
        "\n",
        "        self.model_a_params = {\n",
        "            'learning_rate':0.05\n",
        "            , 'colsample_bytree':1\n",
        "            , 'objective':'reg:squarederror'\n",
        "            , 'n_estimators':1000\n",
        "            , 'max_depth':10\n",
        "        }\n",
        "\n",
        "        self.model_a = [xgb.XGBRegressor(**self.model_a_params) \n",
        "                        for model in range(self.observation_space_n)]\n",
        "\n",
        "        self.model_b_params = {\n",
        "            'learning_rate':0.05\n",
        "            , 'colsample_bytree':0.7\n",
        "            , 'objective':'binary:logistic'\n",
        "            , 'n_estimators':1000\n",
        "            , 'max_depth':10\n",
        "        }\n",
        "\n",
        "        self.model_b = xgb.XGBClassifier(**self.model_b_params)\n",
        "\n",
        "        self.model_b_validation_score = 0\n",
        "\n",
        "        self.model_a_features = [\n",
        "            [0,1,2,3,4]\n",
        "            , [1,4]\n",
        "            , [2,3,4]\n",
        "            , [3,4]\n",
        "        ]\n",
        "        \n",
        "        self.model_a_data_columns = ['Level', 'Sid', 'Pid', 'State', 'Action']\n",
        "\n",
        "        self.rewarded_features = [[2, 1]]\n",
        "        self.action_index = 4\n",
        "        self.episode_index = 5\n",
        "\n",
        "        self.training_data = deque(maxlen=ma_training_data_size)\n",
        "        self.training_data_b = deque(maxlen=mb_training_data_size)\n",
        "        \n",
        "        self.steps = 0\n",
        "        self.episodes = 0\n",
        "\n",
        "        self.ma_mb_switch = ma_mb_switch\n",
        "\n",
        "    def fit_model_a(self):\n",
        "\n",
        "        for idx, m in enumerate(self.model_a):\n",
        "            \n",
        "            X, Y = [], []\n",
        "            for e in range(self.episodes):\n",
        "                \n",
        "                X_append = [x[self.model_a_features[idx]] for x in self.training_data if x[self.episode_index] == e][:-1]\n",
        "                for x in X_append: X.append(x)\n",
        "                \n",
        "                y_append = [y[idx] for y in self.training_data if y[self.episode_index] == e][1:]\n",
        "                for y in y_append: Y.append(y)\n",
        "            \n",
        "            X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
        "\n",
        "            self.model_a[idx].fit(\n",
        "                X_train, y_train\n",
        "                , early_stopping_rounds=50\n",
        "                , eval_set=[(X_test, y_test)]\n",
        "                , eval_metric='rmse'\n",
        "                , verbose=False)\n",
        "\n",
        "    def fit_model_b(self):\n",
        "        \n",
        "        if self.model_b_validation_score >= 0.96: return\n",
        "\n",
        "        X, Y = [], []\n",
        "\n",
        "        for row in self.training_data_b:\n",
        "            X.append(row[:self.action_index])\n",
        "            Y.append(row[self.action_index])\n",
        "\n",
        "        X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "        if len(self.training_data_b) < self.training_data_b.maxlen:\n",
        "            self.model_b.fit(X, Y)\n",
        "        else:\n",
        "            kfold = KFold(n_splits=5)\n",
        "            results = cross_val_score(self.model_b, X, Y, cv=kfold)\n",
        "            if results.mean() > self.model_b_validation_score:\n",
        "                self.model_b.fit(X, Y)\n",
        "                self.model_b_validation_score = results.mean()\n",
        "\n",
        "    def adjust_ma_mb_switch(self, ma_mb_switch_factor, ma_mb_switch_minimum, ma_mb_switch):\n",
        "        self.ma_mb_switch = max(self.ma_mb_switch * ma_mb_switch_factor, ma_mb_switch_minimum)\n",
        "\n",
        "    def transfer_data_to_model_b(self, mb_threshold_for_model_fit):\n",
        "        batch = list(itertools.islice(self.training_data, len(self.training_data)-mb_threshold_for_model_fit, len(self.training_data)))\n",
        "        for row in batch: self.training_data_b.append(row)\n",
        " \n",
        "    def receive_custom_reward(self, state):\n",
        "        reward = 0\n",
        "        for feature in self.rewarded_features:\n",
        "            reward += 1 - min(((state[feature[0]])**2)**0.5, 1)\n",
        "            reward *= feature[1]\n",
        "        return reward\n",
        "\n",
        "    def run_episode(self, test=False, ma_prediction_timesteps=2):\n",
        "\n",
        "        terminal_state = None\n",
        "        episode_steps = 0\n",
        "        state = self.env.reset()\n",
        "        \n",
        "        while True:\n",
        "            \n",
        "            action = random.randrange(self.action_space) \n",
        "\n",
        "            if test:\n",
        "\n",
        "                if self.ma_mb_switch > np.random.rand():\n",
        "                \n",
        "                    level = 0\n",
        "                    sid = 0\n",
        "                    pid = 0\n",
        "                    best_reward = 0\n",
        "\n",
        "                    data = [dict(zip(\n",
        "                                self.model_a_data_columns\n",
        "                                , [level, sid, None, state, None]))]\n",
        "\n",
        "                    while level < ma_prediction_timesteps:\n",
        "\n",
        "                        states = [row['State'] for row in data if row['Level'] == level]\n",
        "                        level += 1\n",
        "\n",
        "                        for s in states:\n",
        "                            for a in range(self.action_space):\n",
        "\n",
        "                                predicted_state = []\n",
        "\n",
        "                                for idx, m in enumerate(self.model_a):\n",
        "\n",
        "                                    x_state = np.append(np.array(s).copy(), a)\n",
        "                                    x_state = x_state[self.model_a_features[idx]]\n",
        "\n",
        "                                    predicted_state_feature = self.model_a[idx].predict([x_state])[0]\n",
        "                                    predicted_state.append(predicted_state_feature)\n",
        "\n",
        "                                sid += 1\n",
        "                                \n",
        "                                data.append(\n",
        "                                    dict(zip(\n",
        "                                        self.model_a_data_columns\n",
        "                                        , [level, sid, pid, np.array(predicted_state), a])))\n",
        "\n",
        "                            pid += 1\n",
        "                    \n",
        "                    leaf_states = [{'Pid': row['Pid'], 'State': row['State']}\n",
        "                                    for row in data if row['Level'] == level]\n",
        "                    \n",
        "                    rewards = np.array([self.receive_custom_reward(row['State']) \n",
        "                                for row in leaf_states])\n",
        "                    \n",
        "                    best_reward_idx = np.random.choice(np.flatnonzero(rewards == rewards.max()))\n",
        "\n",
        "                    pid_search = leaf_states[best_reward_idx]\n",
        "                    \n",
        "                    while level > 1:\n",
        "                        level -= 1\n",
        "                        pid_state = [row for row in data if row['Sid'] == pid_search['Pid']][0]\n",
        "                        pid_search = pid_state.copy()\n",
        "                    action = pid_state['Action']\n",
        "\n",
        "                else:\n",
        "\n",
        "                    action = np.int(self.model_b.predict([state])[0])\n",
        "            \n",
        "            next_state, _, done, _ = self.env.step(action)\n",
        "\n",
        "            if done:\n",
        "                terminal_state = state\n",
        "                break\n",
        "\n",
        "            episode_steps += 1\n",
        "\n",
        "            row = np.append(np.append(state, action), np.array([self.episodes]))\n",
        "\n",
        "            self.training_data.append(row)\n",
        "\n",
        "            state = next_state\n",
        "        \n",
        "        self.steps += episode_steps\n",
        "        self.episodes += 1\n",
        "\n",
        "        return episode_steps, terminal_state "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqcJM-WCFYT",
        "colab_type": "text"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBACYtEVCFYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MA_TRAINING_DATA_SIZE = 800\n",
        "MA_PREDICTION_TIMESTEPS = 2\n",
        "\n",
        "MB_TRAINING_DATA_SIZE = 2200\n",
        "MB_THRESHOLD_FOR_MODEL_FIT = 195\n",
        "\n",
        "MA_MB_SWITCH = 1\n",
        "MA_MB_SWITCH_MINIMUM = 0\n",
        "MA_MB_SWITCH_FACTOR = 0.8\n",
        "\n",
        "MAXIMUM_EPISODES = 1000\n",
        "EPISODES_TO_SOLVE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on3V1ML9CFYW",
        "colab_type": "text"
      },
      "source": [
        "## Run main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdUDo0_sCFYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c4a7e0c-1b43-4d8a-91b5-af2a592db240"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    solved_envs = []\n",
        "    for _ in range(10):\n",
        "        \n",
        "        episode_list = []\n",
        "\n",
        "        xgba = XGBAgent(MA_TRAINING_DATA_SIZE, MB_TRAINING_DATA_SIZE, MA_MB_SWITCH)\n",
        "        \n",
        "        episode_steps = xgba.run_episode(test=False, ma_prediction_timesteps=0)\n",
        "\n",
        "        while True:\n",
        "\n",
        "            xgba.fit_model_a()\n",
        "            episode_steps, terminal_state = xgba.run_episode(test=True, ma_prediction_timesteps=MA_PREDICTION_TIMESTEPS)\n",
        "            episode_list.append(episode_steps)\n",
        "\n",
        "            if episode_steps >= MB_THRESHOLD_FOR_MODEL_FIT:\n",
        "                xgba.transfer_data_to_model_b(MB_THRESHOLD_FOR_MODEL_FIT)\n",
        "                xgba.adjust_ma_mb_switch(MA_MB_SWITCH_FACTOR, MA_MB_SWITCH_MINIMUM, MA_MB_SWITCH)\n",
        "                xgba.fit_model_b()\n",
        "            else:\n",
        "                pass\n",
        "                print(xgba.episodes , episode_steps, xgba.ma_mb_switch, 'ts:', terminal_state)\n",
        "  \n",
        "            if len(episode_list) > EPISODES_TO_SOLVE:\n",
        "\n",
        "                if np.mean(episode_list[-EPISODES_TO_SOLVE:]) >= 195.0:\n",
        "                    \n",
        "                    print ('Solved after', xgba.episodes-EPISODES_TO_SOLVE, 'episodes')\n",
        "                    solved_envs.append(xgba.episodes-EPISODES_TO_SOLVE)\n",
        "                    break\n",
        "\n",
        "            if xgba.episodes > MAXIMUM_EPISODES:\n",
        "                print('Not solved!')\n",
        "                solved_envs.append(MAXIMUM_EPISODES)\n",
        "                break\n",
        "    \n",
        "    plt.bar([idx for idx, x in enumerate(solved_envs)],solved_envs)\n",
        "    plt.ylabel('Solved after number of episodes')\n",
        "    plt.show()\n",
        "    \n",
        "    print('Solved on average after',np.mean(solved_envs),'episodes')\n",
        "    #xgba.env.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 11 1 ts: [ 0.11204035  0.93515262 -0.18717905 -1.65404634]\n",
            "4 12 0.8 ts: [ 0.2187099   0.39497073 -0.20540378 -0.75659415]\n",
            "5 9 0.8 ts: [-0.13062763 -1.33981815  0.17212555  2.12648525]\n",
            "6 33 0.8 ts: [0.06436639 0.47875399 0.20092831 0.43460335]\n",
            "Solved after 4 episodes\n",
            "2 24 1 ts: [ 0.07224096  0.45465536 -0.19960459 -1.2992316 ]\n",
            "3 9 1 ts: [-0.16366952 -1.00983668  0.19319376  1.59128336]\n",
            "4 34 1 ts: [-0.12776961 -0.43462541  0.20548697  0.78050213]\n",
            "5 10 1 ts: [-0.11400343 -1.59151461  0.17013461  2.36614785]\n",
            "6 175 1 ts: [-0.07201697 -1.31402424  0.20217316  1.91016946]\n",
            "16 110 0.13421772800000006 ts: [0.00603842 0.31731152 0.20326706 0.32890267]\n",
            "23 155 0.03518437208883203 ts: [-2.39684823 -1.67000541 -0.08290812 -0.24565296]\n",
            "34 182 0.0037778931862957215 ts: [-2.38403441 -1.46765912 -0.04835893 -0.02939146]\n",
            "39 128 0.0015474250491067279 ts: [-2.38135155 -2.54195518 -0.15461271  0.11196481]\n",
            "40 136 0.0015474250491067279 ts: [-2.37425052 -2.18565787 -0.11271568  0.13050728]\n",
            "46 145 0.0005070602400912927 ts: [-2.38076403 -1.98824764 -0.08752387  0.0410439 ]\n",
            "50 149 0.0002596148429267419 ts: [-2.38059785 -2.39836139 -0.15253225  0.009467  ]\n",
            "59 188 4.3556142965880224e-05 ts: [-2.39493944 -1.42633856 -0.03436443  0.19574514]\n",
            "71 167 3.7414441915671226e-06 ts: [-2.39170881 -1.99923202 -0.1102413   0.13683867]\n",
            "76 172 1.5324955408658941e-06 ts: [-2.36483778 -2.14214566 -0.12523469  0.21338995]\n",
            "82 136 5.021681388309363e-07 ts: [-2.35366751 -2.87952857 -0.17679697  0.2267296 ]\n",
            "85 130 3.213876088517993e-07 ts: [-2.39799578 -2.21282281 -0.10237962 -0.02404358]\n",
            "96 127 3.450873173395297e-08 ts: [-2.38229139 -2.3601944  -0.14774133 -0.1051861 ]\n",
            "105 177 5.789604461865838e-09 ts: [-2.39549489 -2.03658784 -0.1079453   0.19868016]\n",
            "116 184 6.216540455122368e-10 ts: [-2.37672252 -1.82992258 -0.08090372  0.19881387]\n",
            "119 159 3.978585891278316e-10 ts: [-2.39742482 -1.66248329 -0.08169917 -0.03447116]\n",
            "120 172 3.978585891278316e-10 ts: [-2.38096127 -1.84820454 -0.09202558 -0.13918552]\n",
            "123 152 2.5462949704181227e-10 ts: [-2.36932642 -1.78962962 -0.07774836  0.06236985]\n",
            "140 127 7.167183174969023e-12 ts: [-2.37751892 -2.39394449 -0.14577725  0.01522205]\n",
            "147 183 1.87883406621908e-12 ts: [-2.39109596 -1.66925248 -0.08596947 -0.18974484]\n",
            "167 170 2.7076852481648806e-14 ts: [-2.38347127 -1.81717234 -0.09244951 -0.08986707]\n",
            "173 141 8.872543021186684e-15 ts: [-2.38337933 -2.39502684 -0.1563143  -0.08567451]\n",
            "177 184 4.542742026847583e-15 ts: [-2.39674957 -1.46922458 -0.06304964 -0.30441225]\n",
            "181 158 2.3258839177459632e-15 ts: [-2.37875465 -1.82637708 -0.09159045 -0.12725736]\n",
            "194 164 1.5983352577618037e-16 ts: [-2.37494839e+00 -1.84704195e+00 -9.79079762e-02  1.51010468e-03]\n",
            "Solved after 105 episodes\n",
            "2 43 1 ts: [-0.03911621  0.19804815  0.20676083  0.60518302]\n",
            "3 16 1 ts: [-0.14042812 -1.53022403  0.19016135  2.32746643]\n",
            "4 68 1 ts: [-0.13809265 -1.19150282  0.19859125  1.71226845]\n",
            "9 156 0.40960000000000013 ts: [ 0.41551634  0.81219185 -0.18485648 -1.2634762 ]\n",
            "15 76 0.13421772800000006 ts: [ 0.50342975  0.80457131 -0.19903969 -0.64950474]\n",
            "Solved after 3 episodes\n",
            "2 29 1 ts: [ 0.19056018  0.95833115 -0.20483765 -1.40916534]\n",
            "3 32 1 ts: [-0.04262433 -0.74657287  0.18939561  1.29901853]\n",
            "Solved after 2 episodes\n",
            "2 9 1 ts: [ 0.07278171  0.58305824 -0.19336574 -1.0896092 ]\n",
            "3 11 1 ts: [ 0.15222761  1.41404212 -0.19887371 -2.21115739]\n",
            "4 19 1 ts: [ 0.05975499  1.37296895 -0.16946563 -2.06645696]\n",
            "5 35 1 ts: [-0.11415218 -0.62921884  0.19673629  1.01071609]\n",
            "Solved after 3 episodes\n",
            "2 9 1 ts: [ 0.14804185  1.37231181 -0.1852993  -2.20418142]\n",
            "3 22 1 ts: [-0.07440849 -0.80596171  0.19573739  1.66378028]\n",
            "4 153 1 ts: [-0.07955716  0.18190337 -0.20062075 -0.80768465]\n",
            "9 19 0.40960000000000013 ts: [ 0.07163187  0.19256742 -0.20035741 -0.79134977]\n",
            "10 50 0.40960000000000013 ts: [0.18515459 0.72000491 0.20779439 0.28456469]\n",
            "Solved after 3 episodes\n",
            "2 9 1 ts: [ 0.17824148  1.71183737 -0.16877775 -2.66457952]\n",
            "3 18 1 ts: [ 0.1268798   1.15442308 -0.1755906  -1.84198732]\n",
            "4 43 1 ts: [ 0.05724736  0.25358718 -0.20141863 -1.08545941]\n",
            "5 82 1 ts: [ 0.1719123   1.13638986 -0.17888513 -1.6404562 ]\n",
            "10 141 0.40960000000000013 ts: [0.01388317 0.16016426 0.20790211 0.54028214]\n",
            "Solved after 3 episodes\n",
            "2 29 1 ts: [ 0.28737104  0.61397757 -0.20062633 -0.75323314]\n",
            "3 55 1 ts: [-0.09943158 -0.608351    0.1962331   1.10123339]\n",
            "Solved after 2 episodes\n",
            "2 44 1 ts: [-0.06627201  0.01156477 -0.20112497 -1.00228924]\n",
            "3 23 1 ts: [-0.10551057 -1.03361966  0.18893276  1.62854564]\n",
            "4 10 1 ts: [-0.08525726 -1.16553837  0.18133037  1.93822395]\n",
            "6 18 0.8 ts: [ 0.16130328  0.05035488 -0.20762317 -0.37435738]\n",
            "11 174 0.32768000000000014 ts: [-0.27265068  0.01092548 -0.1959788  -0.9869105 ]\n",
            "16 84 0.13421772800000006 ts: [-1.02107237 -1.45130745 -0.20298924 -0.56948596]\n",
            "18 191 0.10737418240000006 ts: [-0.54669383 -0.53445985 -0.20861024 -0.71936639]\n",
            "28 179 0.014411518807585602 ts: [-1.74703379 -1.21728078 -0.20437714 -0.51647751]\n",
            "29 132 0.014411518807585602 ts: [-0.80240954 -1.11920407 -0.20872    -0.28317163]\n",
            "49 180 0.00020769187434139353 ts: [-0.63612239 -0.73660696 -0.20918972 -0.68386526]\n",
            "51 144 0.00016615349947311482 ts: [-1.18578454 -1.43302669 -0.20604738 -0.23694042]\n",
            "54 118 0.0001063382396627935 ts: [-0.97333164 -1.49287784 -0.20710144 -0.15816576]\n",
            "66 170 9.134385233318167e-06 ts: [-1.18603691 -1.03105241 -0.20188019 -0.68251115]\n",
            "71 169 3.7414441915671226e-06 ts: [-0.36029589 -0.55116257 -0.20794245 -0.45129402]\n",
            "80 68 6.277101735386704e-07 ts: [-0.5015726  -1.10533159 -0.20587942 -0.2755836 ]\n",
            "83 85 4.017345110647491e-07 ts: [-0.80286229 -1.31070707 -0.20734849 -0.23762746]\n",
            "87 169 2.056880696651516e-07 ts: [-1.29290734 -1.21914507 -0.20456736 -0.68591422]\n",
            "88 114 2.056880696651516e-07 ts: [-0.69914249 -1.08421682 -0.20549046 -0.34485447]\n",
            "89 139 2.056880696651516e-07 ts: [-0.8740458  -1.2983643  -0.20881797 -0.31971151]\n",
            "104 76 9.046256971665371e-09 ts: [-0.58628584 -1.09030313 -0.20570384 -0.34170743]\n",
            "107 159 5.789604461865838e-09 ts: [-1.36345588 -1.23446042 -0.2034136  -0.68195635]\n",
            "116 145 9.713344461128698e-10 ts: [-0.94301702 -1.30229084 -0.2063421  -0.38597651]\n",
            "122 193 3.182868713022653e-10 ts: [-0.51506305 -0.90100911 -0.20123314 -0.42211833]\n",
            "124 112 2.5462949704181227e-10 ts: [-1.2415752  -1.86556898 -0.20858948 -0.05154291]\n",
            "126 93 2.0370359763344983e-10 ts: [-0.92092056 -1.3047751  -0.20457171 -0.41278267]\n",
            "128 147 1.6296287810675988e-10 ts: [-1.16837654 -1.67489149 -0.20873965 -0.17100768]\n",
            "142 172 8.958978968711279e-12 ts: [-2.30205695 -1.84717702 -0.20725387 -0.34202092]\n",
            "149 136 2.3485425827738497e-12 ts: [-1.05506659 -1.48398314 -0.20586169 -0.34187453]\n",
            "151 170 1.87883406621908e-12 ts: [-0.663585   -0.71266431 -0.20386171 -0.69280957]\n",
            "157 67 6.156563468186683e-13 ts: [-0.58084478 -0.89126213 -0.20932756 -0.67977368]\n",
            "162 190 2.521728396569266e-13 ts: [-1.09688682 -1.47619139 -0.20690182 -0.27907287]\n",
            "167 146 1.0328999512347717e-13 ts: [-1.19688138 -1.42554532 -0.20625453 -0.30391717]\n",
            "173 117 3.384606560206101e-14 ts: [-1.25690985 -1.66932698 -0.20778669 -0.27922536]\n",
            "180 88 8.872543021186684e-15 ts: [-0.6398671  -1.08147536 -0.20562715 -0.3456616 ]\n",
            "202 144 8.183476519740436e-17 ts: [-0.65602489 -1.10409126 -0.20332616 -0.40503245]\n",
            "205 170 5.2374249726338796e-17 ts: [-1.24090219 -1.05904065 -0.19988851 -0.67788633]\n",
            "207 174 4.189939978107104e-17 ts: [-0.6945755  -1.09477903 -0.20868188 -0.41354511]\n",
            "212 73 1.7161994150326704e-17 ts: [-0.5723426  -1.29659602 -0.20830127 -0.06452854]\n",
            "217 112 7.02955280397382e-18 ts: [-1.01543767 -1.10696954 -0.2029645  -0.68279913]\n",
            "225 84 1.474204072195931e-18 ts: [-0.75372704 -1.06975086 -0.20577992 -0.68319824]\n",
            "226 183 1.474204072195931e-18 ts: [-0.42514854 -0.92837223 -0.20804836 -0.09880578]\n",
            "228 91 1.179363257756745e-18 ts: [-0.8200678  -1.30244245 -0.20536367 -0.31242852]\n",
            "233 146 4.830671903771628e-19 ts: [-0.40932908 -0.73458847 -0.20490988 -0.34868493]\n",
            "243 191 6.483618076376628e-20 ts: [-0.82088661 -0.92350098 -0.20548528 -0.68500629]\n",
            "257 173 3.564406732517384e-21 ts: [-0.35505343 -0.53308902 -0.19595794 -0.68775692]\n",
            "266 185 5.980082166329839e-22 ts: [-1.41180158 -1.58145964 -0.20800527 -0.29351666]\n",
            "274 88 1.2541141275282958e-22 ts: [-0.54172992 -1.09543614 -0.2065373  -0.28634893]\n",
            "279 104 5.136851466355901e-23 ts: [-1.03403526 -1.44057456 -0.20669025 -0.40364473]\n",
            "280 147 5.136851466355901e-23 ts: [-0.37793183 -0.54789545 -0.20647967 -0.44579193]\n",
            "283 139 3.287584938467777e-23 ts: [-0.99324118 -1.26388515 -0.20682693 -0.18679022]\n",
            "286 139 2.1040543606193775e-23 ts: [-0.87615608 -1.30002226 -0.20267242 -0.34330672]\n",
            "289 148 1.3465947907964016e-23 ts: [-1.20082406 -1.48611937 -0.20359997 -0.37854568]\n",
            "295 162 4.41252181048165e-24 ts: [-1.29151375 -1.42011651 -0.20563158 -0.38947879]\n",
            "299 145 2.2592111669666054e-24 ts: [-0.53557435 -0.92211995 -0.20256618 -0.37871631]\n",
            "300 174 2.2592111669666054e-24 ts: [-1.17203234 -1.03842106 -0.20624973 -0.67794389]\n",
            "309 179 3.790327373781082e-25 ts: [-0.50199677 -0.92188598 -0.20704725 -0.18780274]\n",
            "318 137 6.359114106063799e-26 ts: [-0.8488934  -0.92145821 -0.20377034 -0.68687359]\n",
            "320 127 5.0872912848510393e-26 ts: [-0.78881244 -0.92836711 -0.20326105 -0.67589336]\n",
            "325 98 2.0837545102749863e-26 ts: [-0.56748842 -0.71930294 -0.19833768 -0.67336666]\n",
            "333 185 4.369949938732209e-27 ts: [-1.45157196 -1.23868184 -0.2088046  -0.69296042]\n",
            "337 99 2.237414368630891e-27 ts: [-0.45327357 -0.91246775 -0.20358004 -0.3364441 ]\n",
            "342 130 9.164449253912132e-28 ts: [-1.03350916 -1.44487028 -0.2058449  -0.35081032]\n",
            "344 73 7.331559403129705e-28 ts: [-0.5773351  -0.90180715 -0.20925438 -0.68926363]\n",
            "345 110 7.331559403129705e-28 ts: [-1.05624989 -1.43125023 -0.20696429 -0.22762932]\n",
            "348 150 4.692198018003012e-28 ts: [-0.51051714 -0.72509613 -0.20886868 -0.69174072]\n",
            "349 173 4.692198018003012e-28 ts: [-1.17700679 -1.25678061 -0.20474418 -0.30415763]\n",
            "352 119 3.003006731521928e-28 ts: [-1.37507752 -1.67054075 -0.20564523 -0.34104646]\n",
            "360 169 6.297761573024677e-29 ts: [-1.75687474 -1.62896913 -0.20725175 -0.19364812]\n",
            "363 93 4.0305674067357936e-29 ts: [-0.81531421 -1.31348801 -0.20646485 -0.22809773]\n",
            "365 163 3.224453925388635e-29 ts: [-0.78754027 -0.86040981 -0.20202271 -0.45329725]\n",
            "373 156 6.762169998536629e-30 ts: [-0.95763043 -1.07614357 -0.20659006 -0.4477605 ]\n",
            "376 175 4.327788799063443e-30 ts: [-0.76452437 -0.93755815 -0.20666569 -0.44321188]\n",
            "377 149 4.327788799063443e-30 ts: [-0.86848205 -0.92193714 -0.20144328 -0.67502014]\n",
            "386 173 7.260824748426802e-31 ts: [-1.0899556  -1.21715951 -0.20712488 -0.41242268]\n",
            "387 80 7.260824748426802e-31 ts: [-0.8540911  -1.46467559 -0.2059233  -0.34159709]\n",
            "390 84 4.646927838993154e-31 ts: [-0.80652618 -1.07088419 -0.20692438 -0.68756072]\n",
            "395 138 1.9033816428515962e-31 ts: [-1.59887532 -1.49064657 -0.20916858 -0.36242088]\n",
            "399 87 9.745314011400174e-32 ts: [-0.68776406 -1.27646088 -0.2055031  -0.27884526]\n",
            "400 59 9.745314011400174e-32 ts: [-0.32912352 -0.93357988 -0.20819786 -0.09862405]\n",
            "405 171 3.9916806190695126e-32 ts: [-1.30108398 -1.59598537 -0.20742539 -0.14374784]\n",
            "407 142 3.19334449525561e-32 ts: [-0.95685439 -1.09900182 -0.2079395  -0.68770096]\n",
            "413 156 1.0463951242053584e-32 ts: [-0.6296013  -1.0973437  -0.2062604  -0.40223955]\n",
            "424 83 1.1235582092889685e-33 ts: [-0.71115167 -0.92962177 -0.20343316 -0.68713295]\n",
            "427 191 7.190772539449398e-34 ts: [-0.94018987 -0.83563683 -0.19811568 -0.67467445]\n",
            "431 123 3.681675540198092e-34 ts: [-0.88288523 -1.22990389 -0.2061518  -0.41501667]\n",
            "435 150 1.8850178765814234e-34 ts: [-0.58524635 -0.72842609 -0.20590856 -0.68907606]\n",
            "438 104 1.206411441012111e-34 ts: [-0.60079322 -1.09668387 -0.20558425 -0.29302143]\n",
            "442 104 6.17682657798201e-35 ts: [-0.71387113 -1.11255494 -0.20693223 -0.41190662]\n",
            "455 133 4.244682903279415e-36 ts: [-1.34924966 -1.25143635 -0.20419125 -0.68841285]\n",
            "463 191 8.901745239978235e-37 ts: [-1.58053324 -1.57980501 -0.20339185 -0.34584374]\n",
            "465 181 7.121396191982588e-37 ts: [-0.99901287 -1.30529647 -0.20790305 -0.31325952]\n",
            "468 115 4.557693562868857e-37 ts: [-0.5264047  -0.92406497 -0.2073     -0.34201544]\n",
            "472 152 2.333539104188855e-37 ts: [-0.64550288 -1.10344625 -0.20616069 -0.3037646 ]\n",
            "482 190 3.1320231676338363e-38 ts: [-0.82221192 -1.12997095 -0.20480003 -0.23616032]\n",
            "485 173 2.0044948272856556e-38 ts: [-0.6108411  -0.92041557 -0.20068174 -0.45473598]\n",
            "491 75 6.568328650049638e-39 ts: [-0.53335633 -1.29084603 -0.20929053 -0.09395315]\n",
            "496 149 2.6903874150603326e-39 ts: [-0.78344465 -0.92559802 -0.20527993 -0.68424375]\n",
            "497 171 2.6903874150603326e-39 ts: [-0.70751714 -1.31102385 -0.20809219 -0.07595624]\n",
            "507 146 3.6109768628919095e-40 ts: [-1.13994769 -1.10937165 -0.2026563  -0.68224091]\n",
            "510 174 2.3110251922508223e-40 ts: [-0.3920131  -0.72498481 -0.20807054 -0.46105232]\n",
            "511 147 2.3110251922508223e-40 ts: [-1.41428833 -1.63486388 -0.20747049 -0.19345088]\n",
            "533 159 2.1315445134673196e-42 ts: [-0.47672885 -0.53775824 -0.19939999 -0.67264359]\n",
            "536 163 1.3641884886190846e-42 ts: [-1.3266335  -1.58929293 -0.20512346 -0.27283324]\n",
            "541 188 5.5877160493837715e-43 ts: [-0.62237107 -1.10454815 -0.20505386 -0.27327676]\n",
            "558 76 1.5728022448660573e-44 ts: [-0.44790528 -1.09847057 -0.20918271 -0.19509466]\n",
            "561 145 1.0065934367142766e-44 ts: [-0.73764345 -0.91846354 -0.20366101 -0.68079279]\n",
            "563 186 8.052747493714214e-45 ts: [-0.73017174 -0.7390194  -0.20616234 -0.68111599]\n",
            "565 168 6.442197994971371e-45 ts: [-1.0295611  -1.48596647 -0.20782419 -0.28320654]\n",
            "566 140 6.442197994971371e-45 ts: [-0.93633582 -1.12037517 -0.2068157  -0.45808947]\n",
            "568 173 5.1537583959770976e-45 ts: [-0.77505985 -0.92903519 -0.20547977 -0.68502033]\n",
            "577 150 8.646571782112134e-46 ts: [-1.17955032 -1.05072747 -0.20114793 -0.68291177]\n",
            "579 141 6.9172574256897075e-46 ts: [-1.00952973 -1.23895309 -0.20413617 -0.30197707]\n",
            "580 166 6.9172574256897075e-46 ts: [-0.60492796 -0.73787428 -0.20036955 -0.67692991]\n",
            "582 98 5.533805940551766e-46 ts: [-0.94839557 -1.45220387 -0.20312675 -0.39015807]\n",
            "600 125 1.2461023185904798e-47 ts: [-0.89161278 -0.92263831 -0.20381202 -0.69394556]\n",
            "607 162 3.266582462045828e-48 ts: [-1.211391   -1.42484972 -0.20846725 -0.39173128]\n",
            "608 150 3.266582462045828e-48 ts: [-0.77726367 -1.08000425 -0.20687857 -0.35738306]\n",
            "613 112 1.3379921764539717e-48 ts: [-0.5197738  -0.73156958 -0.204568   -0.6802869 ]\n",
            "646 147 1.0600666159890971e-51 ts: [-0.92138546 -1.29695829 -0.20513678 -0.30528441]\n",
            "648 175 8.480532927912778e-52 ts: [-1.54514163 -1.60401108 -0.20413135 -0.34849646]\n",
            "649 175 8.480532927912778e-52 ts: [-0.879497   -0.88854421 -0.20509983 -0.67447809]\n",
            "653 165 4.342032859091343e-52 ts: [-2.02109205 -1.62939474 -0.20375157 -0.30024946]\n",
            "659 143 1.4227973272670516e-52 ts: [-1.35594828 -1.61210887 -0.20926332 -0.16783752]\n",
            "666 149 3.729777825590941e-53 ts: [-0.9035761  -1.23512967 -0.20657924 -0.18579765]\n",
            "668 179 2.983822260472753e-53 ts: [-0.81483782 -0.8916975  -0.2025818  -0.6848632 ]\n",
            "673 191 1.22217359788964e-53 ts: [-0.48051248 -0.54128265 -0.2021608  -0.68342779]\n",
            "676 141 7.821911026493697e-54 ts: [-0.5153007  -0.92452205 -0.20579908 -0.32556038]\n",
            "679 95 5.006023056955967e-54 ts: [-0.44756321 -0.93005161 -0.20614101 -0.22549953]\n",
            "681 167 4.004818445564774e-54 ts: [-1.36335551 -1.61732349 -0.2079873  -0.16170058]\n",
            "682 133 4.004818445564774e-54 ts: [-0.72434552 -1.29332163 -0.20849358 -0.17087005]\n",
            "686 140 2.0504670441291647e-54 ts: [-0.81962956 -1.10451944 -0.20457806 -0.4217443 ]\n",
            "690 94 1.0498391265941325e-54 ts: [-0.98983864 -1.44843923 -0.20247674 -0.40067007]\n",
            "692 156 8.39871301275306e-55 ts: [-0.50844043 -0.70985255 -0.20238683 -0.68872448]\n",
            "696 161 4.3001410625295674e-55 ts: [-0.85976968 -0.85067588 -0.20783231 -0.68338303]\n",
            "707 133 4.617241307937798e-56 ts: [-0.82323042 -1.3125842  -0.20813151 -0.0715304 ]\n",
            "709 172 3.6937930463502386e-56 ts: [-0.51964701 -1.09394052 -0.20774949 -0.18915395]\n",
            "713 145 1.8912220397313224e-56 ts: [-0.64113049 -1.27841442 -0.20640765 -0.19123135]\n",
            "723 136 2.5383552531626393e-57 ts: [-1.4870172  -1.45722384 -0.20648581 -0.3512966 ]\n",
            "724 69 2.5383552531626393e-57 ts: [-0.59122704 -1.28343176 -0.20780403 -0.16218524]\n",
            "731 162 6.654145994850672e-58 ts: [-0.5807643  -1.09370252 -0.20610275 -0.33791418]\n",
            "737 137 2.180430559592669e-58 ts: [-0.92825523 -1.2935082  -0.20327339 -0.39558855]\n",
            "741 127 1.1163804465114468e-58 ts: [-1.06672738 -1.31029829 -0.20528957 -0.30635676]\n",
            "742 164 1.1163804465114468e-58 ts: [-1.13884988 -1.04887336 -0.20518141 -0.6956769 ]\n",
            "743 85 1.1163804465114468e-58 ts: [-0.62109266 -0.91783286 -0.20585334 -0.44556362]\n",
            "746 152 7.144834857673261e-59 ts: [-1.13732177 -1.48755393 -0.20285663 -0.37308524]\n",
            "751 144 2.926524357702968e-59 ts: [-1.410797   -1.46028984 -0.20568812 -0.3254393 ]\n",
            "753 106 2.3412194861623744e-59 ts: [-0.92141832 -1.10791537 -0.2055193  -0.686903  ]\n",
            "754 96 2.3412194861623744e-59 ts: [-0.616305   -1.11836923 -0.20796704 -0.34587435]\n",
            "777 85 1.7275150672647664e-61 ts: [-0.6520429  -1.28862578 -0.20619044 -0.27228112]\n",
            "779 158 1.3820120538118131e-61 ts: [-1.00540582 -1.48409879 -0.20619846 -0.28471849]\n",
            "784 96 5.660721372413187e-62 ts: [-0.52994623 -0.71726635 -0.20737637 -0.68568825]\n",
            "806 51 5.221093921474205e-64 ts: [-0.30836107 -0.53684657 -0.20159681 -0.68126369]\n",
            "813 146 1.3686784449509345e-64 ts: [-0.68882161 -1.10298411 -0.20275998 -0.40308299]\n",
            "819 76 4.484885528415223e-65 ts: [-0.46212472 -0.71745944 -0.20357616 -0.68538895]\n",
            "824 173 1.8370091124388758e-65 ts: [-1.48528721 -1.6220477  -0.20757988 -0.1944998 ]\n",
            "834 124 2.465591893868426e-66 ts: [-0.54794075 -0.72481935 -0.20762368 -0.68862349]\n",
            "847 160 1.694341847911616e-67 ts: [-1.23521714 -1.4192179  -0.20444717 -0.38431156]\n",
            "873 107 6.401042522480994e-70 ts: [-0.56831551 -0.93151427 -0.2071809  -0.35252728]\n",
            "883 106 8.591333841987884e-71 ts: [-0.66103577 -1.1219904  -0.20533009 -0.224621  ]\n",
            "889 170 2.8152082733425905e-71 ts: [-1.00506802 -1.03357784 -0.20942044 -0.45427197]\n",
            "890 96 2.8152082733425905e-71 ts: [-0.75742711 -1.09633183 -0.2063711  -0.35744987]\n",
            "894 149 1.4413866359514065e-71 ts: [-1.16554613 -1.21239147 -0.20541905 -0.67983556]\n",
            "898 151 7.379899576071204e-72 ts: [-0.42830213 -0.54072694 -0.19916584 -0.6737901 ]\n",
            "902 147 3.7785085829484567e-72 ts: [-1.04043309 -1.22235441 -0.20416165 -0.34568489]\n",
            "905 143 2.4182454930870127e-72 ts: [-0.97553533 -0.87769754 -0.19815846 -0.67485244]\n",
            "912 154 6.339285465398021e-73 ts: [-1.20095045 -1.05821706 -0.20001594 -0.68659098]\n",
            "925 167 4.356323800622825e-74 ts: [-1.41637673 -1.60924241 -0.20609227 -0.28591315]\n",
            "938 164 2.9936429207138353e-75 ts: [-1.49407067 -1.46837392 -0.20103187 -0.46245223]\n",
            "945 177 7.847655298076079e-76 ts: [-0.67697952 -1.30448368 -0.20856794 -0.04478478]\n",
            "950 154 3.2143996100919626e-76 ts: [-0.63112058 -1.11333841 -0.20573486 -0.21483209]\n",
            "955 171 1.3166180802936681e-76 ts: [-1.27524694 -1.59159495 -0.20907191 -0.15018645]\n",
            "958 163 8.426355713879477e-77 ts: [-0.71870884 -1.28742788 -0.2088235  -0.16071096]\n",
            "969 72 9.047730553893777e-78 ts: [-0.52533693 -1.105223   -0.20589577 -0.30118811]\n",
            "975 186 2.964760347899914e-78 ts: [-0.57208981 -0.75034949 -0.20588493 -0.44690877]\n",
            "977 148 2.3718082783199315e-78 ts: [-1.01106832 -1.05443982 -0.2089355  -0.45184344]\n",
            "983 64 7.771941366398754e-79 ts: [-0.319866   -0.73543397 -0.20624796 -0.35391465]\n",
            "993 139 1.0431323123472565e-79 ts: [-0.62174515 -0.91123891 -0.20083357 -0.45532157]\n",
            "996 89 6.676046799022443e-80 ts: [-0.39299185 -0.54436628 -0.20214215 -0.68306689]\n",
            "998 159 5.3408374392179545e-80 ts: [-0.83298522 -0.91829716 -0.20385408 -0.68680255]\n",
            "1000 142 4.272669951374364e-80 ts: [-1.1402128  -1.41482165 -0.20431946 -0.28178058]\n",
            "1001 180 4.272669951374364e-80 ts: [-0.68862979 -0.73792701 -0.20237551 -0.68346834]\n",
            "Not solved!\n",
            "6 120 0.40960000000000013 ts: [ 0.92814865  1.17176035 -0.18597376 -1.33744075]\n",
            "8 193 0.32768000000000014 ts: [-0.76216165 -1.37959415  0.17503652  1.73734427]\n",
            "Solved after 2 episodes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTQZLvzugwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Solved on average after 112.7 episodes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}